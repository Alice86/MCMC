{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 202C - HW1\n",
    "\n",
    "## Problem 1\n",
    "### i)\n",
    "I think step 3 can be more effective, because a larger proportion of samples are effective (bigger $\\pi(x,y)$ and bigger importance weight $\\pi(x,y)/g(x,y)$). The distribution of step 3 is similar to that in the middle of Fig. 2.4 in the notebook, while that of step 2 has the same mean and lower variance hence is farther from the truth.\n",
    "![Fig. 1-1](1-1.png)\n",
    "The plot above confirms that guess. It can be observed that: step 1 fluctuates around the ture value within less than 100 samples, and gets more and more stable as the sample size increase, which is justified by law of large number; step 2 does not converge to the same level until tens of thousands of samples, and the fluatuation is severe; step 3 converge in approximately thousands of samples, and the estimation gets stable with millions of samples. It can be concluded that with a sampling distribution closer to the original, the convergnece is faster and much more stable (smaller variance in estimation). \n",
    "\n",
    "### iiï¼‰\n",
    "We use 500 simulations to get a stable estimate of \"true\" effective sample size. The sampling processures in question i) is repeated to average over estimation errors (absolute distance to the truth) with different sample sizes. A plot of the errors is displayed in the appendix. \n",
    "\n",
    "We consider error less than .05 as convergence, and find the estimates of \"true\" ESS, the log plots in question are displayed below:\n",
    "\n",
    "Step 2 | Step 3 \n",
    "- | - \n",
    "<img src=\"1-2-a.png\" width=\"432\" height=\"288\" align=\"center\"/> | <img src=\"1-2-b.png\" width=\"432\" height=\"288\"> \n",
    "\n",
    "It can be observed that in general the estimator $ess(n)$ increases at a similar rate to that of the \"truth\". Therefore, it can be used as a general estimation. However, it is always greater than 0 and keeps increase even after convergence, which indicates that it tends to exaggerate the true effective sample size. Moreover, the variance of this estimation is depedent on the sampling process, as $\\theta_2$ and $ess(n_2)$ are both very volatile due to poor sampling distribution. \n",
    "\n",
    "\n",
    "## Problem 2\n",
    "\n",
    "### Designs\n",
    "\n",
    "#### Design 1: naive\n",
    "For each move, there are equal possibilities to move to all available neighbors. The walks stops only when there is no available actions.\n",
    "\n",
    "#### Design 2: .05 probability to stop\n",
    "Based on Design 1, now there is also a 0.05 probablity for the walk to stop for each move. The probablities of walking directions are modiofied accordingly to ensure a probabilities sum of 1.\n",
    "\n",
    "#### Design 3: higher probablity towards (n, n)\n",
    "In this design, unequal possibilities to move to the neighbors are used to favor pathes that hits (n,n). The probablities of moving left and down are set to be 0.2, when the current state is father from (n,n) horizontally than vertically, there is 0.35 probability moving right and 0.25 otherwise.\n",
    "\n",
    "### Task i)\n",
    "\n",
    "The 3 designs and the results with $M = 10^7$ samples are as follow:\n",
    "\n",
    "<img src=\"2-1-0.png\" width=\"560\" height=\"350\" align=\"center\"/>\n",
    "\n",
    "$K_1 = 3.369 \\times 10^{25}, K_2 = 3.962 \\times 10^{25}, K_3 = 3.760 \\times 10^{25}$. \n",
    "\n",
    "Design 1 is the most naive method, it is like sampling from the original distribution. It yields a good result while the program can be slow due to the hard sampling process. Possible improvements are discussed with the other two designs.\n",
    "\n",
    "Design 2 favors shorter pathes by introducing a probability of early termination, so as to reduce the number of move-sampling steps required to improve the sampling efficiency. Whereas, the convergence plot shows that it requires a larger sample size to converge to the same level as Design 1.  \n",
    "\n",
    "Design 3 seems to be the most efficient as it converges the fastest, however the difference with Design 1 is very small. Actually, it is very similar to Design 1 with only a small amount of probability change, while move-sampling with different probability requires more computation power. The advantage of this design is more obvious in the nest task, as we will discuss later.\n",
    "\n",
    "When plotting the length distribution, I think we still need to weight with $w_l = \\frac{1}{g(x_{l})}/\\sum_{i=1}^M\\frac{1}{g(x_i)} = \\frac{1}{g(x_{l})M}$. The distributions of path lengths and the longest pathes is displayed below:\n",
    "\n",
    "<img src=\"2-1-d.png\" width=\"560\" height=\"350\" align=\"center\"/>\n",
    "\n",
    "Design 1 | Design 2 | Design 3\n",
    "- | - | - \n",
    "<img src=\"2-1-1.png\" width=\"260\" height=\"260\" align=\"center\"/> | <img src=\"2-1-2.png\" width=\"260\" height=\"260\"> | <img src=\"2-1-3.png\" width=\"260\" height=\"260\" align=\"center\"/>\n",
    "\n",
    "Using equal probability and no length constraints, Design 1 obtains a distribution resembling gaussian. As for Design 2, the distribution is biased towards left which confirms that this design favors shorter paths. Moreover, as the probability of getting a long path is low, hence corresponding weight is high, as a result, there is a peak at length = 104 where there is only one sample. Design 3 obtains a distribution very similar to that in Design 1, yet with smaller varaince due to the constraint we added.\n",
    "\n",
    "### Task ii): hitting (n,n)\n",
    "\n",
    "In this task, we focus on pathes that hit target (n,n), in general the sampling converges faster with less than $10^6$ samples. However, multiple attempts are required to get a sample in this case. \n",
    "\n",
    "On average, in Design 1 about 10 attempts are need to get a sample hitting (n,n), so $10^7$ attempts are required in total, the program takes a similar amount of time as in task i) (in fact the two task can be accomplished in one program simultaneously). \n",
    "\n",
    "Design 2 favors shorter pathes, which makes it a lot harder to hit (n, n). On avarage 68 attempts are need for one sample. In the appendix, a plot of estimated K over number of attempts indicates that, Design 2 can not converge within $10^7$ attempts, when only 146022 samples are achieved.\n",
    "\n",
    "In contract, Design 3 explicitly favors pathes that hits (n,n) by giving a higher probability for such move direction. We limit this difference of probablity to a small amount (.1 difference at most) so that the resulting samples are still diverse enough. Whereas, with such a small change, the average number of attempts need to get a sample reduced to 5.\n",
    "\n",
    "Therefore, we try Design 1 and Design 3 for this task, and the results with $M = 10^6$ samples are as follow:\n",
    "\n",
    "<img src=\"2-2-0.png\" width=\"560\" height=\"350\" align=\"center\"/>\n",
    "\n",
    "$K_1 = 3.392 \\times 10^{24}, K_3 = 2.596 \\times 10^{24}$. \n",
    "\n",
    "The rates of convergence against sample size are similar, whereas, as we discussed before, Design 3 takes around half attempts to get the same level of sample size.\n",
    "\n",
    "The distributions of path lengths and the longest pathes is displayed below:\n",
    "\n",
    "<img src=\"2-2-d.png\" width=\"560\" height=\"350\" align=\"center\"/>\n",
    "\n",
    "Design 1 | Design 3\n",
    "- | - \n",
    "<img src=\"2-2-1.png\" width=\"260\" height=\"260\" align=\"center\"/> | <img src=\"2-2-3.png\" width=\"260\" height=\"260\" align=\"center\"/>\n",
    "\n",
    "We always get lengths of even number because we only ends at (n,n), apart from that the distributions are similar to that in task i) similar to that of gaussian.\n",
    "\n",
    "\n",
    "## Appendix\n",
    "<img src=\"Apdx1.png\" width=\"480\" height=\"320\" align=\"center\"/>\n",
    "<img src=\"apdx2.png\" width=\"480\" height=\"320\" align=\"center\"/>\n",
    "\n",
    "---------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "#### i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define \\pi(x) and g(x)\n",
    "def p(x, y):\n",
    "    return 0.5/np.pi*np.exp(-0.5*((x-2)**2+(y-2)**2))    \n",
    "def g(x, y, sigma):\n",
    "    return 0.5/np.pi/sigma**2*np.exp(-0.5/sigma**2*(x**2+y**2))\n",
    "ns = []\n",
    "for i in range(6):\n",
    "    ns += list(range(int(10**(i)),int(10**(i+1)),int(10**(i))))\n",
    "##ns = np.logspace(1,6,6, dtype=int)\n",
    "# importance sampling\n",
    "np.random.seed(7) \n",
    "cache1 = []\n",
    "for n in ns:\n",
    "    x = np.random.normal(2,1,n)\n",
    "    y = np.random.normal(2,1,n)\n",
    "    theta1 = np.mean(np.sqrt(x**2+y**2))\n",
    "    cache1.append(theta1)    \n",
    "cache2 = []\n",
    "ws2 = []\n",
    "ess_est2 = []\n",
    "sigma = 1\n",
    "for n in ns:\n",
    "    x = np.random.normal(0,sigma,n)\n",
    "    y = np.random.normal(0,sigma,n)\n",
    "    w = p(x,y)/g(x,y,sigma)\n",
    "    ws2.append(w) \n",
    "    ess_est2.append(n/(1+np.var(w,ddof=1)))\n",
    "    theta2 = np.mean(np.sqrt(x**2+y**2)*w)\n",
    "    cache2.append(theta2)\n",
    "cache3 = []\n",
    "ws3 = []\n",
    "ess_est3 = []\n",
    "sigma = 4\n",
    "for n in ns:\n",
    "    x = np.random.normal(0,sigma,n)\n",
    "    y = np.random.normal(0,sigma,n)\n",
    "    w = p(x,y)/g(x,y,sigma)\n",
    "    ws3.append(w) \n",
    "    ess_est3.append(n/(1+np.var(w,ddof=1)))\n",
    "    theta3 = np.mean(np.sqrt(x**2+y**2)*w)\n",
    "    cache3.append(theta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1-1 for one simulation seed=7\n",
    "plt.figure(3)\n",
    "plt.title('Convergence of the estimation')\n",
    "plt.xscale('symlog')\n",
    "plt.xlabel('log sample size')\n",
    "plt.ylabel('estimated theta')\n",
    "plt.plot(ns, cache1, label='theta 1')\n",
    "plt.plot(ns, cache2, label='theta 2')\n",
    "plt.plot(ns, cache3, label='theta 3')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(\"1-1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a more stable error measure: 500 simulation \n",
    "def avg_err():\n",
    "    cache1 = []\n",
    "    cache2 = []\n",
    "    cache3 = []\n",
    "    for n in ns:\n",
    "        x = np.random.normal(2,1,n)\n",
    "        y = np.random.normal(2,1,n)\n",
    "        theta1 = np.mean(np.sqrt(x**2+y**2))\n",
    "        cache1.append(theta1)    \n",
    "        x = np.random.normal(0,sigma,n)\n",
    "        y = np.random.normal(0,sigma,n)\n",
    "        w = p(x,y)/g(x,y,sigma)\n",
    "        theta2 = np.mean(np.sqrt(x**2+y**2)*w)\n",
    "        cache2.append(theta2)\n",
    "        x = np.random.normal(0,4,n)\n",
    "        y = np.random.normal(0,4,n)\n",
    "        w = p(x,y)/g(x,y,sigma)\n",
    "        theta3 = np.mean(np.sqrt(x**2+y**2)*w)\n",
    "        cache3.append(theta3)\n",
    "    err1.append(np.abs([x-3 for x in cache1]))\n",
    "    err2.append(np.abs([x-3 for x in cache2]))\n",
    "    err3.append(np.abs([x-3 for x in cache3]))\n",
    "\n",
    "err1 = []\n",
    "err2 = []\n",
    "err3 = []\n",
    "for i in range(500):\n",
    "    avg_err()\n",
    "avg_err1 = np.mean(err1, axis=0)\n",
    "avg_err2 = np.mean(err2, axis=0)\n",
    "avg_err3 = np.mean(err3, axis=0)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the average error\n",
    "plt.title('Average error in 500 simulations')\n",
    "plt.xscale('symlog')\n",
    "plt.xlabel('log sample size')\n",
    "plt.ylabel('estimation error')\n",
    "plt.plot(ns, avg_err1, label='theta 1')\n",
    "plt.plot(ns, avg_err2, label='theta 2')\n",
    "plt.plot(ns, avg_err3, label='theta 3')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(\"Apdx1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate \"true\" ess\n",
    "ess_true2 = []\n",
    "ess_true3 = []\n",
    "cvg1 = np.argwhere(avg_err1 < 5e-2)[0] #20\n",
    "cvg2 = np.argwhere(avg_err2 < 5e-2)[0] #38\n",
    "cvg3 = np.argwhere(avg_err3 < 5e-2)[0] #38\n",
    "maxi = np.max(avg_err1)\n",
    "for i in range(len(ns)):\n",
    "    if i > cvg2:\n",
    "        ess_true2.append(ns[cvg1[0]])\n",
    "    else:\n",
    "        if avg_err2[i] > maxi:\n",
    "            ess_true2.append(0)\n",
    "        else:\n",
    "            reach = np.argwhere(avg_err1 <= avg_err2[i])\n",
    "            if len(reach) > 1:\n",
    "                reach = reach[0]         \n",
    "            ess_true2.append(ns[reach[0]])\n",
    "    if i > cvg3:\n",
    "        ess_true3.append(ns[cvg1[0]])\n",
    "    else:\n",
    "        if avg_err3[i] > maxi:\n",
    "            ess_true3.append(0)\n",
    "        else:\n",
    "            reach = np.argwhere(avg_err1 <= avg_err3[i])\n",
    "            if len(reach) > 1:\n",
    "                reach = reach[0]         \n",
    "            ess_true3.append(ns[reach[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.title('ESS for theta2')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('ESS')\n",
    "plt.yscale('symlog')\n",
    "plt.xscale('symlog')\n",
    "plt.plot(ns, ess_est2, label='estimated')\n",
    "plt.plot(ns, ess_true2, label='true')\n",
    "plt.legend(loc='upper left')\n",
    "#plt.savefig(\"1-2-a.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.title('ESS for theta3')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('ESS')\n",
    "plt.yscale('symlog')\n",
    "plt.xscale('symlog')\n",
    "plt.plot(ns, ess_est3, label='estimated')\n",
    "plt.plot(ns, ess_true3, label='true')\n",
    "plt.legend(loc='upper left')\n",
    "#plt.savefig(\"1-2-b.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Parallel computation\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "class Worker(Thread):\n",
    "    \"\"\" Thread executing tasks from a given tasks queue \"\"\"\n",
    "    def __init__(self, tasks):\n",
    "        Thread.__init__(self)\n",
    "        self.tasks = tasks\n",
    "        self.daemon = True\n",
    "        self.start()\n",
    "    def run(self):\n",
    "        while True:\n",
    "            func, args, kargs = self.tasks.get()\n",
    "            try:\n",
    "                func(*args, **kargs)\n",
    "            except Exception as e:\n",
    "                # An exception happened in this thread\n",
    "                print(e)\n",
    "            finally:\n",
    "                # Mark this task as done, whether an exception happened or not\n",
    "                self.tasks.task_done()\n",
    "class ThreadPool:\n",
    "    \"\"\" Pool of threads consuming tasks from a queue \"\"\"\n",
    "    def __init__(self, num_threads):\n",
    "        self.tasks = Queue(num_threads)\n",
    "        for _ in range(num_threads):\n",
    "            Worker(self.tasks)\n",
    "    def add_task(self, func, *args, **kargs):\n",
    "        \"\"\" Add a task to the queue \"\"\"\n",
    "        self.tasks.put((func, args, kargs))\n",
    "    def map(self, func, args_list):\n",
    "        \"\"\" Add a list of tasks to the queue \"\"\"\n",
    "        for args in args_list:\n",
    "            self.add_task(func, args)\n",
    "    def wait_completion(self):\n",
    "        \"\"\" Wait for completion of all the tasks in the queue \"\"\"\n",
    "        self.tasks.join()\\\n",
    "\n",
    "pool = ThreadPool(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "### Design 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saw1(i):\n",
    "    state = np.array([0,0])\n",
    "    path = []\n",
    "    p = 1\n",
    "    end = False\n",
    "    r, l, u, d = np.array([1,0]), np.array([-1,0]), np.array([0,1]), np.array([0,-1])\n",
    "    while list(state) not in path:\n",
    "        last = np.copy(state)\n",
    "        path.append(list(last))\n",
    "        # candidates        \n",
    "        moves = []\n",
    "        if all(state+r >= 0) and all(state+r <= 10) and list(state+r) not in path:\n",
    "            moves.append(r)\n",
    "        if all(state+l >= 0) and all(state+l <= 10) and list(state+l) not in path:\n",
    "            moves.append(l)\n",
    "        if all(state+u >= 0) and all(state+u <= 10) and list(state+u) not in path:\n",
    "            moves.append(u)\n",
    "        if all(state+d >= 0) and all(state+d <= 10) and list(state+d) not in path:\n",
    "            moves.append(d)\n",
    "        # choose move\n",
    "        num = len(moves)\n",
    "        if num == 0:\n",
    "            break\n",
    "        else:\n",
    "            idx = np.random.randint(num, size=1)\n",
    "            prob = 1/num            \n",
    "            move = moves[idx[0]] \n",
    "            # take move, cumulate p(r)\n",
    "            state += move\n",
    "            p = p*prob #g(x)\n",
    "    # whether end\n",
    "        if all(state == 10):\n",
    "            end = np.copy(p)\n",
    "            pathe = np.copy(path)\n",
    "            le = len(pathe)\n",
    "    if length > len(path1):\n",
    "        path1 = np.copy(path)\n",
    "    if le > len(pathe1):\n",
    "        pathe1 = pathe\n",
    "#    s = len(design1) # attempts\n",
    "#    se = sum([x[0]!=0 for x in design1])\n",
    "#    if s in ns or (le!=0 and se in ns): \n",
    "#        # i)\n",
    "#        K_all = sum([1/x[1] for x in design1])/s\n",
    "#        # ii)\n",
    "#        w = np.array([1/x[0] for x in design1 if x[0]!=0]) # w_0\n",
    "#        ends = np.array([x[0] for x in design1])\n",
    "#        att = np.argwhere(ends!=0) # cumulative attempts\n",
    "#        u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "#        weights = w/u #weights: 1/g(x)\n",
    "#        K_end = sum(weights)/se\n",
    "#        cache1.append((s, se, K_all, K_end))\n",
    "#        print(\"Sample[%.1e] Sample_end[%.1e] Design3: %.3e, %.3e\" % (s, se, K_all, K_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# record\n",
    "design1 = [] # probablity of hitting (n,n) - 0 if not hitting, probability, length, length of ending path\n",
    "path1 = [] # longest path\n",
    "pathe1 = [] # longest path hitting (n,n)\n",
    "cache1 = []\n",
    "# run\n",
    "M = int(1e7)\n",
    "pool.map(saw1, range(M))\n",
    "pool.wait_completion()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i)\n",
    "K_all = np.mean([1/x[1] for x in design1[:int(1e7)]]) #3.3689065344252283e+25\n",
    "# ii)\n",
    "w = np.array([1/x[0] for x in design1 if x[0]!=0]) # w_0\n",
    "ends = np.array([x[0] for x in design1])\n",
    "att = np.argwhere(ends!=0) # cumulative attempts\n",
    "u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "weights = w/u #weights: 1/g(x)\n",
    "K_end = sum(weights)/se #\n",
    "#pe = [x[2] for x in design1 if x[0]]\n",
    "#l = [len(x[2]) for x in design1]\n",
    "#le = [len(x[2]) for x in design1 if x[0]]\n",
    "#path1 = p[np.argmax(l)]\n",
    "#pathe1 = pe[np.argmax(le)]\n",
    "#e, g, p = zip(*design1)\n",
    "#ll = tuple(l)\n",
    "#design1 = list(zip(*[e,g,ll]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saw2(eps):\n",
    "    state = np.array([0,0])\n",
    "    path = []\n",
    "    p = 1\n",
    "    end = 0\n",
    "    le = 0\n",
    "    r, l, u, d = np.array([1,0]), np.array([-1,0]), np.array([0,1]), np.array([0,-1])\n",
    "    while list(state) not in path:\n",
    "        last = np.copy(state)\n",
    "        path.append(list(last))\n",
    "        # candidates        \n",
    "        moves = [np.array([0,0])]\n",
    "        if all(state+r >= 0) and all(state+r <= 10) and list(state+r) not in path:\n",
    "            moves.append(r)\n",
    "        if all(state+l >= 0) and all(state+l <= 10) and list(state+l) not in path:\n",
    "            moves.append(l)\n",
    "        if all(state+u >= 0) and all(state+u <= 10) and list(state+u) not in path:\n",
    "            moves.append(u)\n",
    "        if all(state+d >= 0) and all(state+d <= 10) and list(state+d) not in path:\n",
    "            moves.append(d)\n",
    "        # choose move\n",
    "        num = len(moves)\n",
    "        if num == 1:\n",
    "            break\n",
    "        else:\n",
    "            probs = [eps] + list(np.repeat((1-eps)/(num-1),num-1))\n",
    "            idx = np.random.choice(num, 1, p = probs)\n",
    "            choice = idx[0]\n",
    "            if choice == 0:\n",
    "                break\n",
    "            move = moves[choice]\n",
    "            prob = probs[choice]\n",
    "            # take move, cumulate p(r)\n",
    "            state += move\n",
    "            p = p*prob #g(x)\n",
    "    # whether end\n",
    "#        if all(state == 10):\n",
    "#            end = np.copy(p)\n",
    "#            pathe = np.copy(path)\n",
    "#            le = len(pathe)\n",
    "    length = len(path)\n",
    "    design2.append((end,p,length,le))\n",
    "    if length > len(path2):\n",
    "        path2 = np.copy(path)\n",
    "#    if le > len(pathe2):\n",
    "#        pathe2 = pathe\n",
    "#    s = len(design2) # attempts\n",
    "#    se = sum([x[0]!=0 for x in design2])\n",
    "#    if s in ns or (le!=0 and se in ns): \n",
    "#        # i)\n",
    "#        K_all = sum([1/x[1] for x in design2])/s\n",
    "#        # ii)\n",
    "#        w = np.array([1/x[0] for x in design2 if x[0]!=0]) # w_0\n",
    "#        ends = np.array([x[0] for x in design2])\n",
    "#        att = np.argwhere(ends!=0) # cumulative attempts\n",
    "#        u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "#        weights = w/u #weights: 1/g(x)\n",
    "#        K_end = sum(weights)/se\n",
    "#        cache2.append((s, se, K_all, K_end))\n",
    "#        print(\"Sample[%.1e] Sample_end[%.1e] Design3: %.3e, %.3e\" % (s, se, K_all, K_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# record\n",
    "design2 = [] # probablity of hitting (n,n) - 0 if not hitting, probability, length, length of ending path\n",
    "path2 = [] # longest path\n",
    "#pathe2 = [] # longest path hitting (n,n)\n",
    "cache2 = []\n",
    "# run\n",
    "M = int(1e7)\n",
    "pool.map(saw2, range(M))\n",
    "pool.wait_completion()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i)\n",
    "K_all = np.mean([1/x[1] for x in design2[:int(1e7)]]) #3.9621050204425594e+25\n",
    "# ii)\n",
    "#w = np.array([1/x[0] for x in design if x[0]!=0]) # w_0\n",
    "#ends = np.array([x[0] for x in design2])\n",
    "#att = np.argwhere(ends!=0) # cumulative attempts\n",
    "#u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "#weights = w/u #weights: 1/g(x)\n",
    "#K_end = sum(weights)/se #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Design 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saw3(eps):\n",
    "    state = np.array([0,0])\n",
    "    path = []\n",
    "    p = 1\n",
    "    end = 0\n",
    "    le = 0\n",
    "    r, l, u, d = np.array([1,0]), np.array([-1,0]), np.array([0,1]), np.array([0,-1])\n",
    "    while list(state) not in path:\n",
    "        last = np.copy(state)\n",
    "        path.append(list(last))\n",
    "        # candidates        \n",
    "        moves = [r, l, u, d]\n",
    "        # initialize probs with guidance\n",
    "        probs = np.array([0.3,0.2,0.3,0.2])\n",
    "        distance = np.array([10,10]) - state\n",
    "        monitor = distance[0]-distance[1]\n",
    "        if monitor > 0:\n",
    "            probs[0], probs[2] = 0.35, 0.25\n",
    "        if monitor <0:\n",
    "            probs[0], probs[2] = 0.25, 0.35\n",
    "        if any(state+r < 0) or any(state+r > 10) or list(state+r) in path:\n",
    "            probs[0] = 0\n",
    "        if any(state+l < 0) or any(state+l > 10) or list(state+l) in path:\n",
    "            probs[1] = 0\n",
    "        if any(state+u < 0) or any(state+u > 10) or list(state+u) in path:\n",
    "            probs[2] = 0\n",
    "        if any(state+d < 0) or any(state+d > 10) or list(state+d) in path:\n",
    "            probs[3] = 0\n",
    "        plus = 1 - sum(probs)\n",
    "        if plus == 1:\n",
    "            break\n",
    "        # choose move\n",
    "        else:\n",
    "            probs[probs!=0] += plus/sum(probs!=0)\n",
    "            idx = np.random.choice(4, 1, p = probs)\n",
    "            choice = idx[0]\n",
    "            move = moves[choice]\n",
    "            prob = probs[choice]\n",
    "            # take move, cumulate p(r)\n",
    "            state += move\n",
    "            p = p*prob #g(x)\n",
    "    # whether end\n",
    "        if all(state == 10):\n",
    "            end = np.copy(p)\n",
    "            pathe = np.copy(path)\n",
    "            le = len(pathe)\n",
    "    length = len(path)\n",
    "    design3.append((end, p, length,le))\n",
    "    global path3\n",
    "    global pathe3\n",
    "    if length > len(path3):\n",
    "        path3 = np.copy(path)\n",
    "    if le > len(pathe3):\n",
    "        pathe3 = pathe\n",
    "#    s = len(design3) # attempts\n",
    "#    se = sum([x[0]!=0 for x in design3])\n",
    "#    if s in ns or (le!=0 and se in ns): \n",
    "#        # i)\n",
    "#        K_all = sum([1/x[1] for x in design3])/s\n",
    "#        # ii)\n",
    "#        w = np.array([1/x[0] for x in design3 if x[0]!=0]) # w_0\n",
    "#        ends = np.array([x[0] for x in design3])\n",
    "#        att = np.argwhere(ends!=0) # cumulative attempts\n",
    "#        u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "#        weights = w/u #weights: 1/g(x)\n",
    "#        K_end = sum(weights)/se\n",
    "#        cache3.append((s, se, K_all, K_end))\n",
    "#        print(\"Sample[%.1e] Sample_end[%.1e] Design3: %.3e, %.3e\" % (s, se, K_all, K_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record\n",
    "design3 = [] # probablity of hitting (n,n) - 0 if not hitting, probability, length, length of ending path\n",
    "path3 = [] # longest path\n",
    "pathe3 = [] # longest path hitting (n,n)\n",
    "cache3 = []\n",
    "# run\n",
    "M = int(1e7)\n",
    "pool.map(saw3, range(M))\n",
    "pool.wait_completion()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i)\n",
    "K_all = np.mean([1/x[1] for x in design3[:int(1e7)]]) #3.760032560502165e+25\n",
    "# ii)\n",
    "w = np.array([1/x[0] for x in design3 if x[0]!=0]) # w_0\n",
    "ends = np.array([x[0] for x in design3])\n",
    "att = np.argwhere(ends!=0) # cumulative attempts\n",
    "u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "weights = w/u #weights: 1/g(x)\n",
    "K_end = sum(weights)/se #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convergence plot K against M for task i)\n",
    "ns = []\n",
    "for i in range(7):\n",
    "    ns += list(range(int(10**(i)),int(10**(i+1)),int(10**(i))))\n",
    "K_all1 = [np.mean([1/x[1] for x in design1[:ns[0]]])]\n",
    "K_all2 = [np.mean([1/x[1] for x in design2[:ns[0]]])]\n",
    "K_all3 = [np.mean([1/x[1] for x in design3[:ns[0]]])]\n",
    "for i in range(len(ns)-1):\n",
    "    n = ns[i+1]\n",
    "    nl = ns[i]    \n",
    "    K_all1.append((K_all1[i]*nl+np.sum([1/x[1] for x in design1[nl:n]]))/n)\n",
    "    K_all2.append((K_all2[i]*nl+np.sum([1/x[1] for x in design2[nl:n]]))/n)\n",
    "    K_all3.append((K_all3[i]*nl+np.sum([1/x[1] for x in design3[nl:n]]))/n)\n",
    "plt.figure(3)\n",
    "plt.title('Convergence of the estimation')\n",
    "plt.xscale('symlog')\n",
    "plt.yscale('symlog')\n",
    "plt.xlabel('log sample size')\n",
    "plt.ylabel('estimated number of pathes')\n",
    "plt.plot(ns, K_all1, label='Design 1')\n",
    "plt.plot(ns, K_all2, label='Design 2')\n",
    "plt.plot(ns, K_all3, label='Design 3')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(\"2-1-0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convergence plot K against M for task ii)\n",
    "ns = []\n",
    "for i in range(6):\n",
    "    ns += list(range(int(10**(i)),int(10**(i+1)),int(10**(i))))\n",
    "w = np.array([1/x[0] for x in design1 if x[0]!=0]) # w_0\n",
    "ends = np.array([x[0] for x in design1])\n",
    "att = np.argwhere(ends!=0) # cumulative attempts\n",
    "u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "weights1 = w/u #weights: 1/g(x)\n",
    "#w = np.array([1/x[0] for x in design2 if x[0]!=0]) # w_0\n",
    "#ends = np.array([x[0] for x in design2])\n",
    "#att = np.argwhere(ends!=0) # cumulative attempts\n",
    "#u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "#weights2 = w/u #weights: 1/g(x)\n",
    "w = np.array([1/x[0] for x in design3 if x[0]!=0]) # w_0\n",
    "ends = np.array([x[0] for x in design3])\n",
    "att = np.argwhere(ends!=0) # cumulative attempts\n",
    "u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "weights3 = w/u #weights: 1/g(x)\n",
    "K_end1 = sum(weights1[:ns[0]])/ns[0]\n",
    "#K_end2 = sum(weights[:ns[0]])/ns[0]\n",
    "K_end3 = sum(weights3[:ns[0]])/ns[0]\n",
    "for i in range(len(ns)-1):\n",
    "    n = ns[i+1]\n",
    "    nl = ns[i]    \n",
    "    K_end1.append((K_end1[i]*nl+sum(weights1[nl:n]))/n)\n",
    "#    K_end2.append((K_end2[i]*nl+sum(weights2[nl:n]))/n)\n",
    "    K_end3.append((K_end3[i]*nl+sum(weights3[nl:n]))/n)\n",
    "plt.figure(3)\n",
    "plt.title('Convergence of the estimation')\n",
    "plt.xscale('symlog')\n",
    "plt.yscale('symlog')\n",
    "plt.xlabel('log sample size')\n",
    "plt.ylabel('estimated number of pathes')\n",
    "plt.plot(ns, K_end1, label='Design 1')\n",
    "#plt.plot(ns, K_all2, label='Design 2')\n",
    "plt.plot(ns, K_end3, label='Design 3')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(\"2-2-0.png\")\n",
    "# K against num. of attempts\n",
    "K_end1 = []\n",
    "K_end2 = []\n",
    "K_end3 = []\n",
    "d = design[int(3052380):]\n",
    "for i in ns:\n",
    "    w = np.array([1/x[0] for x in d[:i] if x[0]!=0]) # w_0\n",
    "    if len(w) == 0:\n",
    "        K_end1.append(0)\n",
    "    else:\n",
    "        ends = np.array([x[0] for x in d[:i]])\n",
    "        att = np.argwhere(ends!=0) # cumulative attempts\n",
    "        u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "        K_end1.append(np.mean(w/u))\n",
    "    w = np.array([1/x[0] for x in design2[:i] if x[0]!=0]) # w_0\n",
    "    if len(w) == 0:\n",
    "        K_end2.append(0)\n",
    "    else:\n",
    "        ends = np.array([x[0] for x in design2[:i]])\n",
    "        att = np.argwhere(ends!=0) # cumulative attempts\n",
    "        u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "        K_end2.append(np.mean(w/u))\n",
    "    w = np.array([1/x[0] for x in design3[:i] if x[0]!=0]) # w_0\n",
    "    if len(w) == 0:\n",
    "        K_end3.append(0)\n",
    "    else:\n",
    "        ends = np.array([x[0] for x in design3[:i]])\n",
    "        att = np.argwhere(ends!=0) # cumulative attempts\n",
    "        u = np.append(att[0]+1,np.diff(att,axis=0)) # attempts\n",
    "        K_end3.append(np.mean(w/u))\n",
    "plt.figure(3)\n",
    "plt.title('Convergence of the estimation over num. of attempts')\n",
    "plt.xscale('symlog')\n",
    "plt.yscale('symlog')\n",
    "plt.xlabel('log number of attempts')\n",
    "plt.ylabel('estimated number of pathes')\n",
    "plt.plot(ns, K_end1, label='Design 1')\n",
    "plt.plot(ns, K_end2, label='Design 2')\n",
    "plt.plot(ns, K_end3, label='Design 3')\n",
    "plt.legend(loc='upper left')\n",
    "plt.savefig(\"Apdx2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lengths ditribution plots\n",
    "l1 = [x[2] for x in design1]\n",
    "x1 = list(range(max(l1)+1))\n",
    "y1 = np.bincount(l1, weights=[1/x[1] for x in design1])/len(l1)\n",
    "l2 = [x[2] for x in design2]\n",
    "x2 = list(range(max(l2)+1))\n",
    "y2 = np.bincount(l2, weights=[1/x[1] for x in design2])/len(l2)\n",
    "l3 = [x[2] for x in design3]\n",
    "x3 = list(range(max(l3)+1))\n",
    "y3 = np.bincount(l3, weights=[1/x[1] for x in design3])/len(l3)\n",
    "plt.figure(3)\n",
    "plt.title('Distribution of the lengths of SAWs')\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('count')\n",
    "plt.plot(x1, y1, label='Design 1')\n",
    "plt.plot(x2, y2, label='Design 2')\n",
    "plt.plot(x3, y3, label='Design 3')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(\"2-1-l.png\")\n",
    "# task ii)\n",
    "l1 = [x[3] for x in design1 if x[0]!=0]\n",
    "x1 = list(range(max(l1)+1))\n",
    "y1 = np.bincount(l1, weights=[1/x[0] for x in design1 if x[0]!=0])/len(l1)\n",
    "#l2 = [x[2] for x in design2]\n",
    "#x2 = list(range(max(l2)+1))\n",
    "#y2 = np.bincount(l2, weights=[1/x[1] for x in design2 if x[0]])/len(l2)\n",
    "l3 = [x[3] for x in design3 if x[0]]\n",
    "x3 = list(range(max(l3)+1))\n",
    "y3 = np.bincount(l3, weights=[1/x[0] for x in design3 if x[0]!=0])/len(l3)\n",
    "plt.figure(3)\n",
    "plt.title('Distribution of the lengths of ending SAWs')\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('count')\n",
    "plt.plot(x1, y1, label='Design 1')\n",
    "#plt.plot(x2, y2, label='Design 2')\n",
    "plt.plot(x3, y3, label='Design 3')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(\"2-1-b.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path plots\n",
    "x = [c[0] for c in path1]\n",
    "y = [c[1] for c in path1]\n",
    "plt.figure(1)\n",
    "plt.title('Longest path in design 1 (length = %d)' %len(path1))\n",
    "plt.plot(x, y)\n",
    "plt.savefig(\"2-1-1.png\")\n",
    "x = [c[0] for c in path2]\n",
    "y = [c[1] for c in path2]\n",
    "plt.figure(1)\n",
    "plt.title('Longest path in design 1 (length = %d)' %len(path1))\n",
    "plt.plot(x, y)\n",
    "plt.savefig(\"2-1-2.png\")\n",
    "x = [c[0] for c in path3]\n",
    "y = [c[1] for c in path3]\n",
    "plt.figure(1)\n",
    "plt.title('Longest path in design 1 (length = %d)' %len(path1))\n",
    "plt.plot(x, y)\n",
    "plt.savefig(\"2-1-3.png\")\n",
    "# path hitting (n,n)\n",
    "x = [c[0] for c in pathe1]\n",
    "y = [c[1] for c in pathe1]\n",
    "plt.figure(1)\n",
    "plt.title('Longest ending path in design 1 (length = %d)' %len(pathe1))\n",
    "plt.plot(x, y)\n",
    "plt.savefig(\"2-2-1.png\")  \n",
    "x = [c[0] for c in pathe3]\n",
    "y = [c[1] for c in pathe3]\n",
    "plt.figure(1)\n",
    "plt.title('Longest ending path in design 1 (length = %d)' %len(pathe1))\n",
    "plt.plot(x, y)\n",
    "plt.savefig(\"2-2-3.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
